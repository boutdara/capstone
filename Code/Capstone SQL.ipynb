{"cells":[{"cell_type":"code","source":["import os.path\n\nstorageAccount = \"gen10dbcdatalake\"\nstorageContainer = \"group2-capstone\"\nclientSecret = \"~bJ7Q~KslVT~sAmHkOLXL0oeTp1ZkAcndtHPr\"\nclientid = \"2ca50102-5717-4373-b796-39d06568588d\"\nmount_point = \"/mnt/sql\" \n\n\nconfigs = {\"fs.azure.account.auth.type\": \"OAuth\",\n       \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n       \"fs.azure.account.oauth2.client.id\": clientid,\n       \"fs.azure.account.oauth2.client.secret\": clientSecret,\n       \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/d46b54b2-a652-420b-aa5a-2ef7f8fc706e/oauth2/token\",\n       \"fs.azure.createRemoteFileSystemDuringInitialization\": \"true\"}\n\ntry: \n    dbutils.fs.unmount(mount_point)\nexcept:\n    pass\n\ndbutils.fs.mount(\nsource = \"abfss://\"+storageContainer+\"@\"+storageAccount+\".dfs.core.windows.net/\",\nmount_point = mount_point,\nextra_configs = configs)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"99851b7d-10aa-4191-a081-e92b1dbbbbdd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/mnt/sql has been unmounted.\nOut[1]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/mnt/sql has been unmounted.\nOut[1]: True</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# get path for last dataset in pipeline folder, last dataset should be the most up-to-date file from the consumer sent to pipeline folder\nlast = dbutils.fs.ls(\"/mnt/sql/pipeline\")[-1][0][5:] \n\ndf = spark.read.csv(last + '*.csv', header = True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c2b9cab0-fdf9-417f-93f8-440f25caec24"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# change data types for imported dataframe from pipeline folder\nfrom pyspark.sql.types import StringType, DateType, FloatType, LongType, DoubleType, IntegerType\n  \ndf = df \\\n  .withColumn(\"Close\" ,\n              df[\"Close\"]\n              .cast(FloatType()))   \\\n  .withColumn(\"High\",\n              df[\"High\"]\n              .cast(FloatType()))    \\\n  .withColumn(\"Date\"  ,\n              df[\"Date\"]\n              .cast(DateType())) \\\n  .withColumn(\"Low\" ,\n              df[\"Low\"]\n              .cast(FloatType()))   \\\n  .withColumn(\"Open\",\n              df[\"Open\"]\n              .cast(FloatType()))    \\\n  .withColumn(\"Volume\"  ,\n              df[\"Volume\"]\n              .cast(FloatType())) \\\n  .withColumn(\"SP_Close\" ,\n              df[\"SP_Close\"]\n              .cast(FloatType()))   \\\n  .withColumn(\"SP_High\",\n              df[\"SP_High\"]\n              .cast(FloatType()))    \\\n  .withColumn(\"SP_Low\" ,\n              df[\"SP_Low\"]\n              .cast(FloatType()))   \\\n  .withColumn(\"SP_Open\",\n              df[\"SP_Open\"]\n              .cast(FloatType()))    \\\n  .withColumn(\"SP_perc\" ,\n              df[\"SP_perc\"]\n              .cast(FloatType()))   \\\n  .withColumn(\"Perc\",\n              df[\"Perc\"]\n              .cast(FloatType()))    \\\n  .withColumn(\"timestamp\",\n              df[\"timestamp\"]\n              .cast(LongType()))\n  \ndf = df.orderBy(['Date', 'Ticker'])\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3df66ef9-bd4a-4434-88e1-1af514d12019"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# remove first day of trades as percent change from previous day is null\ndf_nonull = df.filter(df.Date != '2007-07-02')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f0b4ec79-e86d-476d-9532-b5310c73bdbe"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# select S&P data from dataframe and include Date column\nfrom pyspark.sql.functions import col\nsp_data = df_nonull.select(col(\"Date\"),col(\"SP_Open\"), col(\"SP_High\"),\n                   col(\"SP_Low\"), col(\"SP_Close\"), col(\"SP_perc\"))\n\n\nsp_data = sp_data.dropDuplicates()\nsp_data = sp_data.orderBy('Date')\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"473d9c01-61e4-48f2-ab33-8fdb009c915d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# create an ID for each entry in S&P dataframe\nfrom pyspark.sql.functions import desc, row_number, monotonically_increasing_id\nfrom pyspark.sql.window import Window\n\n\nsp_data2 = sp_data.withColumn('SP_ID', row_number().over(Window.orderBy(monotonically_increasing_id())))\n\n# rearrange columns so ID is listed first\nsp_data2 = sp_data2.select(\"SP_ID\", \"Date\", \"SP_Open\", \"SP_High\", \"SP_Low\", \"SP_Close\", \"SP_perc\") \n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"65316a9f-cd82-4c68-b36c-d05ccce88e5e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# S&P data with SP_ID, send to database\ndatabase = \"group2\"\ntable = \"dbo.SP_data\"\nuser = \"group2user\"\npassword  = \"everythingIsAwesome!\"\nserver = \"database2108.database.windows.net\"\n\nsp_data2.write.format(\"jdbc\").mode(\"overwrite\") \\\n    .option(\"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\") \\\n    .option(\"dbtable\", table) \\\n    .option(\"user\", user) \\\n    .option(\"password\", password) \\\n    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n    .save()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"884c6d57-b73d-46ad-b91a-90b70531fb9c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# select columns for banking stock data to create new dataframe\nbank_data = df_nonull.select(col(\"Date\"), col(\"Ticker\"), col(\"Open\"), col(\"High\"), col(\"Low\"),\n                      col(\"Close\"), col(\"Volume\"), col(\"Perc\"))\n\nbank_data = bank_data.orderBy(['Date', 'Ticker'])\n\n# add Stock_ID column to give an ID in each entry\nbank_data = bank_data.withColumn('Stock_ID', row_number().over(Window.orderBy(monotonically_increasing_id())))\nbank_data = bank_data.select(\"Stock_ID\", \"Date\", \"Ticker\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Perc\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f900cbc5-669e-41ba-a971-472b6fe3f965"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# get ticker data by selecting Ticker column from dataframe\nticker = bank_data.select('Ticker')\n\n# remove duplicate rows as only 6 banking stocks are included\nticker = ticker.dropDuplicates()\n\n# add a Ticker_ID column to give an ID for each banking stock\nticker = ticker.withColumn('Ticker_ID', row_number().over(Window.orderBy(monotonically_increasing_id())))\nticker = ticker.select('Ticker_ID', 'Ticker')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a07bf057-258b-4795-bc83-6828f8662ccd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# join Ticker table with bank_data on Ticker\nbank_data2 = bank_data.join(ticker, \"Ticker\")\n\n# new dataframe drops Ticker column and retains the Ticker_ID column from the join\nbank_data2 = bank_data2.select(\"Stock_ID\", \"Ticker_ID\", \"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Perc\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"859eea70-5502-4ee8-918d-2ea9fa86c654"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# stock data with Ticker_ID column\ndatabase = \"group2\"\ntable = \"dbo.stock_data\"\nuser = \"group2user\"\npassword  = \"everythingIsAwesome!\"\nserver = \"database2108.database.windows.net\"\n\nbank_data2.write.format(\"jdbc\").mode(\"overwrite\") \\\n    .option(\"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\") \\\n    .option(\"dbtable\", table) \\\n    .option(\"user\", user) \\\n    .option(\"password\", password) \\\n    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n    .save()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0da25d3-4a03-42d0-ba62-ff26ba656277"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# create table for ticker data\ndatabase = \"group2\"\ntable = \"dbo.ticker_data\"\nuser = \"group2user\"\npassword  = \"everythingIsAwesome!\"\nserver = \"database2108.database.windows.net\"\n\nticker.write.format(\"jdbc\").mode(\"overwrite\") \\\n    .option(\"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\") \\\n    .option(\"dbtable\", table) \\\n    .option(\"user\", user) \\\n    .option(\"password\", password) \\\n    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n    .save()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7fda6a0a-ecbb-46bd-b88d-5dff1948f9d8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# use previous mount point to load the Census data\ndf3 = spark.read.csv('/mnt/sql/CombinedFinancial.csv', header = True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d459e33-9f89-4ed1-878e-6dc7d1b7055b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["\n# convert columns to appropriate data types\ndf3 = df3 \\\n  .withColumn(\"FIRM\" ,\n              df3[\"FIRM\"]\n              .cast(IntegerType()))   \\\n  .withColumn(\"ESTAB\",\n              df3[\"ESTAB\"]\n              .cast(IntegerType()))    \\\n  .withColumn(\"PAYANN\"  ,\n              df3[\"PAYANN\"]\n              .cast(IntegerType())) \\\n  .withColumn(\"EMP\" ,\n              df3[\"EMP\"]\n              .cast(IntegerType()))   \\\n  .withColumn(\"RCPTOT\" ,\n              df3[\"RCPTOT\"]\n              .cast(IntegerType()))   \\\n  .withColumn(\"PAYQTR1\" ,\n              df3[\"PAYQTR1\"]\n              .cast(IntegerType()))   \\\n  .withColumn(\"NAICS2017\" ,\n              df3[\"NAICS2017\"]\n              .cast(IntegerType()))   \\\n\ndf3 = df3.select('NAICS2017', 'NAICS2017_LABEL', 'LABELCATEGORY', 'LABELNAME', 'YEAR', 'FIRM',\n                 'ESTAB', 'RCPTOT', 'PAYANN', 'PAYQTR1', 'EMP', 'RCPTOT_IMP', 'PAYANN_IMP', 'EMP_IMP')\n                 "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4452074b-1a89-4075-8c69-841220df7ccf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["database = \"group2\"\ntable = \"dbo.census_data\"\nuser = \"group2user\"\npassword  = \"everythingIsAwesome!\"\nserver = \"database2108.database.windows.net\"\n\ndf3.write.format(\"jdbc\").mode(\"overwrite\") \\\n    .option(\"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\") \\\n    .option(\"dbtable\", table) \\\n    .option(\"user\", user) \\\n    .option(\"password\", password) \\\n    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n    .save()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94fa049a-1574-426f-8c7e-82c72d4ca79e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"25eb2f35-3e80-46cf-a45e-8aa6931e4829"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Capstone SQL","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3352377749356374}},"nbformat":4,"nbformat_minor":0}
